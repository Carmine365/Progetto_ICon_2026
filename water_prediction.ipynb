{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb7573f0",
   "metadata": {},
   "source": [
    "# Predizione della Potabilità dell'Acqua mediante Algoritmi di Apprendimento Supervisionato\n",
    "\n",
    "Questo notebook analizza il dataset sulla qualità dell'acqua per predire se è potabile o meno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd038c5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Importiamo le librerie necessarie\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Aggiungiamo la cartella src al path per importare i moduli personalizzati\n",
    "sys.path.append(os.path.abspath(\"src\"))\n",
    "\n",
    "from data_loader import water_data\n",
    "from ml_models import water_logistic_regression, water_decision_tree, water_knn\n",
    "# Se hai aggiornato anche ml_evaluation.py, importalo qui\n",
    "# from ml_evaluation import metrics_graph_lr, metrics_graph_dt, metrics_graph_knn, comparison_metrics_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae93ebef",
   "metadata": {},
   "source": [
    "### Analisi Esplorativa dei Dati (EDA)\n",
    "Carichiamo il dataset e visualizziamo la correlazione tra le variabili e la distribuzione della classe target (Potability)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f1fbae",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Creiamo l'oggetto water_data\n",
    "data = water_data()\n",
    "\n",
    "# Visualizziamo le prime righe del dataset\n",
    "print(data.get_data().head())\n",
    "\n",
    "# Visualizziamo la matrice di confusione (heatmap)\n",
    "data.get_heatmap()\n",
    "\n",
    "# Visualizziamo la distribuzione della potabilità (0 = Non potabile, 1 = Potabile)\n",
    "data.plot_outcomes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ead7789",
   "metadata": {},
   "source": [
    "### Definizione e Addestramento dei Modelli\n",
    "Utilizzeremo tre algoritmi di classificazione:\n",
    "1. **Regressione Logistica**\n",
    "2. **Albero di Decisione**\n",
    "3. **K-Nearest Neighbors (KNN)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de232d20",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Definizione parametri\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "# --- 1. Regressione Logistica ---\n",
    "print(\"Addestramento Regressione Logistica...\")\n",
    "lr_model = water_logistic_regression(data, iterations=1000, test_size=TEST_SIZE)\n",
    "lr_model.predict()\n",
    "lr_model.get_confusion_matrix()\n",
    "print(\"Metriche LR:\", lr_model.scores)\n",
    "\n",
    "# --- 2. Albero di Decisione ---\n",
    "print(\"\\nAddestramento Albero di Decisione...\")\n",
    "dt_model = water_decision_tree(data, max_d=5, test_size=TEST_SIZE)\n",
    "dt_model.predict()\n",
    "dt_model.get_confusion_matrix()\n",
    "print(\"Metriche DT:\", dt_model.scores)\n",
    "\n",
    "# --- 3. K-Nearest Neighbors ---\n",
    "print(\"\\nAddestramento KNN...\")\n",
    "knn_model = water_knn(data, test_size=TEST_SIZE, neighbors=9)\n",
    "knn_model.predict()\n",
    "knn_model.get_confusion_matrix()\n",
    "print(\"Metriche KNN:\", knn_model.scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4f9adf",
   "metadata": {},
   "source": [
    "### Confronto dei Modelli\n",
    "Confrontiamo le prestazioni dei tre modelli analizzando le metriche di Accuratezza, Precision, Recall e F1-Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217901f4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Creiamo un grafico comparativo\n",
    "models = ['Logistic Regression', 'Decision Tree', 'KNN']\n",
    "accuracies = [lr_model.get_metric(\"Accuracy\"), dt_model.get_metric(\"Accuracy\"), knn_model.get_metric(\"Accuracy\")]\n",
    "precisions = [lr_model.get_metric(\"Precision\"), dt_model.get_metric(\"Precision\"), knn_model.get_metric(\"Precision\")]\n",
    "recalls = [lr_model.get_metric(\"Recall\"), dt_model.get_metric(\"Recall\"), knn_model.get_metric(\"Recall\")]\n",
    "\n",
    "x = range(len(models))\n",
    "width = 0.25\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bar1 = ax.bar([i - width for i in x], accuracies, width, label='Accuracy')\n",
    "bar2 = ax.bar(x, precisions, width, label='Precision')\n",
    "bar3 = ax.bar([i + width for i in x], recalls, width, label='Recall')\n",
    "\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Confronto metriche modelli')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea209c04",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# --- 4. Confronto dei Modelli (Codice diretto nel Notebook) ---\n",
    "\n",
    "models = ['Logistic Regression', 'Decision Tree', 'KNN']\n",
    "\n",
    "# Recuperiamo le metriche dai dizionari 'scores' dei modelli già addestrati\n",
    "accuracies = [lr_model.scores[\"Accuracy\"], dt_model.scores[\"Accuracy\"], knn_model.scores[\"Accuracy\"]]\n",
    "precisions = [lr_model.scores[\"Precision\"], dt_model.scores[\"Precision\"], knn_model.scores[\"Precision\"]]\n",
    "recalls = [lr_model.scores[\"Recall\"], dt_model.scores[\"Recall\"], knn_model.scores[\"Recall\"]]\n",
    "f1_scores = [lr_model.scores[\"F1_score\"], dt_model.scores[\"F1_score\"], knn_model.scores[\"F1_score\"]]\n",
    "\n",
    "# Impostazioni del grafico\n",
    "x = np.arange(len(models))  # posizione delle etichette\n",
    "width = 0.2  # larghezza delle barre\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "# Creazione delle barre affiancate\n",
    "rects1 = ax.bar(x - width*1.5, accuracies, width, label='Accuracy', color='#1f77b4')\n",
    "rects2 = ax.bar(x - width/2, precisions, width, label='Precision', color='#ff7f0e')\n",
    "rects3 = ax.bar(x + width/2, recalls, width, label='Recall', color='#2ca02c')\n",
    "rects4 = ax.bar(x + width*1.5, f1_scores, width, label='F1 Score', color='#d62728')\n",
    "\n",
    "# Etichette, titolo e legenda\n",
    "ax.set_ylabel('Punteggio (0.0 - 1.0)')\n",
    "ax.set_title('Confronto Prestazioni Modelli - Water Potability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models)\n",
    "ax.legend(loc='lower right')\n",
    "\n",
    "# Aggiunge una griglia orizzontale leggera per leggere meglio i valori\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Mostra il grafico\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b0664b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cella finale del notebook\n",
    "from ml_evaluation import comparison_metrics_models\n",
    "\n",
    "# Questo farà partire tutto il calcolo CV e mostrerà il grafico completo\n",
    "comparison_metrics_models(data, test_size=0.2)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
